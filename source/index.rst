.. BME-X documentation master file, created by
   sphinx-quickstart on Sun Mar 30 20:11:24 2025.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.
   

=========
Overview
=========

Significant
------------

.. image:: https://zenodo.org/badge/DOI/10.5281/zenodo.14047881.svg
   :target: https://doi.org/10.5281/zenodo.14047881
   :alt: DOI


A foundation model for the motion correction, super resolution, denoising and harmonization of magnetic resonance images, can improve the performance of machine-learning models across a wide range of tasks.

`BME-X Github Repository <https://github.com/DBC-Lab/Brain_MRI_Enhancement.git>`_

`BME-X dockerhub Repository <https://hub.docker.com/repository/docker/yuesun814/bme-x/general>`_

Method
-------

In structural magnetic resonance (MR) imaging, motion artifacts, low resolution, imaging noise, and variability in acquisition protocols, frequently degrade image quality and confound downstream analyses. Here we report a flexible and easy-to-implement Brain MRI Enhancement foundation (BME-X) model for the motion correction, resolution enhancement, denoising and harmonization of MR images. Our framework also exhibits the capability to estimate high-field-like (7T-like) images from 3T images, handle pathological brain MRIs with multiple sclerosis or gliomas, harmonize MRIs acquired by various scanners, and can be easily extended for "end-to-end" neuroimaging analyses, such as tissue segmentation.

.. image:: https://raw.githubusercontent.com/YueSun814/Img-folder/main/BME-X_flowchart.png
   :width: 1000px
   :align: center  


Intended Usage
---------------

BME-X is designed for researchers and clinicians working with structural MRIs to enhance image quality and perform standardized analyses.

Motion correction and super resolution
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.. image:: https://raw.githubusercontent.com/YueSun814/Img-folder/main/BME-X_BCP_real_images.png
   :width: 1000px
   :align: center  

Performance on 10,963 lifespan images from fetal to adulthood
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. image:: https://raw.githubusercontent.com/YueSun814/Img-folder/main/BME-X_lifespan_real_images.png
   :width: 1000px
   :align: center 

Application on harmonization across scanners (into a latent common space)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.. image:: https://raw.githubusercontent.com/YueSun814/Img-folder/main/BME-X_harmonization.png
   :width: 1000px
   :align: center  
   
Preservation of small lesions during enhancement
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.. image:: https://raw.githubusercontent.com/YueSun814/Img-folder/main/BME-X_spots.png
   :width: 300px
   :align: center  
   
Bias quantification during reconstruction
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.. image:: https://raw.githubusercontent.com/YueSun814/Img-folder/main/BME-X_MR-ART.png
   :width: 1000px
   :align: center  

Enhancement results and the bias quantification for 280 in vivo corrupted T1w images from the `MR-ART <https://openneuro.org/datasets/ds004173/versions/1.0.2>`_ dataset, generated by competing methods and the BME-X model. a, Visual comparison of the enhanced results. The first and the seventh columns show in vivo corrupted images with two levels of real artifacts (i.e., HM1 and HM2) acquired from the same participant. The remaining columns show the enhanced results generated by four competing methods and the BME-X model. b, Quantitative comparison on 280 in vivo corrupted images using tissue volumes (i.e., WM, GM, CSF, ventricle, and hippocampus), mean cortical thickness, as well as the corresponding difference compared with STAND. In each box plot, the midline represents the median value, and its lower and upper edges represent the first and third quartiles. The whiskers go down to the smallest value and up to the largest. The dotted line represents the mean value or a zero value.

How to cite
------------

Sun, Y., Wang, L., Li, G. et al. A foundation model for enhancing magnetic resonance images and downstream segmentation, registration and diagnostic tasks. Nat. Biomed. Eng 9, 521–538 (2025). https://doi.org/10.1038/s41551-024-01283-7

Wang, L., Sun, Y., Seidlitz, J. et al. A lifespan-generalizable skull-stripping model for magnetic resonance images that leverages prior knowledge from brain atlases. Nat. Biomed. Eng 9, 700–715 (2025). https://doi.org/10.1038/s41551-024-01337-w

======================
Installation & Usage
======================

We have integrated the `LifespanStrip <https://github.com/DBC-Lab/Atlases-empowered_Lifespan_Skull_Stripping>`_ framework and the `BME-X <https://github.com/DBC-Lab/Brain_MRI_Enhancement>`_ model into a single Docker image to make it more convenient for everyone to use. By inputting T1w/T2w raw images, this pipeline goes through RAI orientation, intensity inhomogeneity correction, skull stripping, and image enhancement for the brain region. Additionally, the Quality Index (QI) of the original images is provided for reference.


Download
----------

To pull the image, use the following command ::

    docker pull yuesun814/bme-x:v1.0.5
  
How to Run the Container
------------------------- 

Basic Command
^^^^^^^^^^^^^^^

Run the Docker container using the following command ::

    mkdir -p /Local/path/to/the/outputs && \
    docker run --rm --gpus all -u $(id -u):$(id -g) \
        -v /Local/path/to/the/inputs:/data \
        -v /Local/path/to/the/outputs:/results \
        yuesun814/bme-x:v1.0.5 \
        --bids_root /data/test_BIDS_raw \
        --output_dir /results 
   
``--bids_root`` specifies the BIDS dataset to be processed.

``--subject_id`` specifies a subject within the BIDS dataset to be processed (optional).

``--session_id`` specifies a session within the BIDS dataset to be processed (optional).

Example Usage
^^^^^^^^^^^^^^^

For example, using the `test_BIDS_raw <https://github.com/DBC-Lab/Brain_MRI_Enhancement/tree/main/test_BIDS_raw>`_ we provided. The following command will process all the data that meets the criteria within the *test_BIDS_raw*. ::

    docker run --gpus all -v /home/user/data:/app/data yuesun814/bme-x:v1.0.5 --bids_root test_BIDS_raw
    mkdir -p /Local/path/to/the/outputs && \
    docker run --rm --gpus all -u $(id -u):$(id -g) \
      -v /Local/path/to/the/inputs:/data \
      -v /Local/path/to/the/outputs:/results \
      yuesun814/bme-x:v1.0.5 \
      --bids_root test_BIDS_raw \
      --data_base /data \
      --output_dir /results
    
The following command will process a specific subject when the ``--subject_id`` is provided (e.g. 0001). ::
   
    docker run --gpus all -v /home/user/data:/app/data yuesun814/bme-x:v1.0.5 --bids_root test_BIDS_raw --subject_id 0001 
    
The following command will process a specific session when the ``--session_id`` (e.g. V02) is provided. ::
    
    docker run --gpus all -v /home/user/data:/app/data yuesun814/bme-x:v1.0.5 --bids_root test_BIDS_raw --session_id V02
    
Help Information
^^^^^^^^^^^^^^^^^^
::

    docker run --gpus all -v /home/user/data:/app/data yuesun814/bme-x:v1.0.5 --help

========
Outputs
======== 
::

    ├── test_BIDS_raw/
        ├── dataset_description.json
        ├── descriptions.tsv
        ├── sub-0001/
            ├── ses-V02/
                ├── anat/
                    ├── sub-0001_ses-V01_T2w.nii.gz
                    ├── sub-0001_ses-V01_T2w.json
                    ├── sub-0001_ses-V01_desc-brain_mask.nii.gz
                    ├── sub-0001_ses-V01_desc-brain_mask.json
                    ├── sub-0001_ses-V01_desc-preproc_T2w.nii.gz
                    ├── sub-0001_ses-V01_desc-preproc_T2w.json
                    ├── sub-0001_ses-V01_desc-enhanced_T2w.nii.gz
                    ├── sub-0001_ses-V01_desc-enhanced_T2w.json

``dataset_description.json`` 
{"Name":"BME-X Outputs","BIDSVersion":"1.10.0","DatasetType":"derivative","GeneratedBy":[{"Name":"BME-X","Version":"v1.0.4","Container":{"Type":"docker","Tag":"yuesun814/bme-x:v1.0.4"}}]}

``descriptions.tsv`` 
The meaning of derivative files.

``sub-*.json`` 
The sidecar JSON for every NIfTI with fields: Sources (list of bids:raw: paths), SpatialReference (bids:raw: path), SkullStripped (true/false), Type (Brain), and Quality Index (QI): {"QI": {"value": <0..1>, "description": "Quality index [0,1]..."}}

``sub-0001_ses-V01_T2w.nii.gz`` 
T1w/T2w.nii.gz files are raw anats copied from the input data to the derivatives.
    
==================
Acknowledgements
==================

Y.S., Limei Wang and Li Wang were supported by the National Institute of Mental Health under award numbers MH133845, MH117943, MH123202 and MH116225. G.L. was supported by the National Institutes of Health (NIH) under award numbers MH133845, MH117943, MH123202, MH116225, AG075582 and NS128534. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH. This work also uses approaches developed by NIH grants (U01MH110274 and R01MH104324) and the efforts of the UNC/UMN Baby Connectome Project Consortium. Data collection and sharing for the Alzheimer's Disease Neuroimaging Initiative (ADNI) is funded by the National Institute on Aging (National Institutes of Health Grant U19AG024904). The grantee organization is the Northern California Institute for Research and Education. We acknowledge M. M. Pangelinan for her valuable contribution in providing the in vivo low-resolution data used for super-resolution validation. We express our sincere gratitude to all those who have supported us in the validation: J. Bernal, J. Kim, K. A. Vaughn, J. Tuulari, K. Oishi, A. Tapp, Y. Chen, X. Geng, T. F. Vaz and Z. Zariry. We also deeply appreciate all participants who contributed to the datasets involved in this work.

=========
Get Help
=========
    
If you encounter any issues or have concerns, please submit them here https://github.com/DBC-Lab/Brain_MRI_Enhancement/issues

=========
License
=========

MIT License
